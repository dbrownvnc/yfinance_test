import streamlit as st
import yfinance as yf
import google.generativeai as genai
import pandas as pd
import os
import requests
import xml.etree.ElementTree as ET
import urllib.parse
from dateutil import parser
import re
import plotly.graph_objects as go
import time
import datetime
import socket
import concurrent.futures
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import math
import html
from difflib import SequenceMatcher
import json

# ---------------------------------------------------------
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ---------------------------------------------------------
CSV_FILE = "my_portfolio.csv"
mobile_mode = True
chart_height = "350px"
socket.setdefaulttimeout(30)

if 'sidebar_state' not in st.session_state:
    st.session_state['sidebar_state'] = 'expanded'

st.set_page_config(
    layout="wide", 
    page_title="AI Hyper-Analyst V86 (Final)", 
    page_icon="ğŸ“ˆ",
    initial_sidebar_state=st.session_state['sidebar_state']
)

# [ë¡œê·¸ ì‹œìŠ¤í…œ] ì´ˆê¸°í™” ë° í•¨ìˆ˜ ì •ì˜
if 'log_buffer' not in st.session_state:
    st.session_state['log_buffer'] = []

def add_log(message):
    """ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ (ìƒì„¸ ëª¨ë“œ)"""
    timestamp = datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3] 
    log_entry = f"[{timestamp}] {message}"
    st.session_state['log_buffer'].append(log_entry)
    if len(st.session_state['log_buffer']) > 500:
        st.session_state['log_buffer'].pop(0)

# [ë³€ìˆ˜ ì •ì˜] 
opt_targets = [
    "í˜„ê¸ˆê±´ì „ì„± ì§€í‘œ (FCF, ìœ ë™ë¹„ìœ¨, ë¶€ì±„ë¹„ìœ¨)", 
    "í•µì‹¬ ì¬ë¬´ì œí‘œ ë¶„ì„ (ì†ìµ, ëŒ€ì°¨ëŒ€ì¡°, í˜„ê¸ˆíë¦„)",
    "íˆ¬ìê¸°ê´€ ëª©í‘œì£¼ê°€ ë° ì»¨ì„¼ì„œìŠ¤", 
    "í˜¸ì¬/ì•…ì¬ ë‰´ìŠ¤ íŒë‹¨", 
    "ê¸°ìˆ ì  ì§€í‘œ (RSI/ì´í‰ì„ )",
    "ì™¸êµ­ì¸/ê¸°ê´€ ìˆ˜ê¸‰ ë¶„ì„", 
    "ê²½ìŸì‚¬ ë¹„êµ ë° ì—…í™©", 
    "ë‹¨ê¸°/ì¤‘ê¸° ë§¤ë§¤ ì „ëµ",
    "íˆ¬ìì„±í–¥ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì ì •ë³´ìœ ë¹„ì¤‘"
]

# ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
if 'analysis_results' not in st.session_state: st.session_state['analysis_results'] = {} 
if 'is_analyzing' not in st.session_state: st.session_state['is_analyzing'] = False
if 'targets_to_run' not in st.session_state: st.session_state['targets_to_run'] = []
if 'current_mode' not in st.session_state: st.session_state['current_mode'] = "MAIN"
if 'prompt_mode' not in st.session_state: st.session_state['prompt_mode'] = False
if 'proc_index' not in st.session_state: st.session_state['proc_index'] = 0
if 'proc_stage' not in st.session_state: st.session_state['proc_stage'] = 0 
if 'temp_data' not in st.session_state: st.session_state['temp_data'] = {}
if 'select_all_state' not in st.session_state: st.session_state['select_all_state'] = False
if 'new_ticker_input' not in st.session_state: st.session_state['new_ticker_input'] = ""

# ì²´í¬ë°•ìŠ¤ ìƒíƒœ ì´ˆê¸°í™”
for opt in opt_targets:
    if f"focus_{opt}" not in st.session_state: st.session_state[f"focus_{opt}"] = True
if 'focus_all' not in st.session_state: st.session_state['focus_all'] = True

# ---------------------------------------------------------
# 2. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜
# ---------------------------------------------------------
def load_data_to_state():
    if 'portfolio_df' not in st.session_state:
        add_log("ğŸ“¥ [INIT] í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ë¡œë“œ ì‹œë„...")
        if os.path.exists(CSV_FILE):
            try:
                df = pd.read_csv(CSV_FILE)
                if df.empty:
                    st.session_state['portfolio_df'] = pd.DataFrame(columns=['ticker', 'name'])
                else:
                    st.session_state['portfolio_df'] = df.reset_index(drop=True)
                    add_log(f"âœ… [INIT] ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©.")
            except Exception as e:
                st.session_state['portfolio_df'] = pd.DataFrame(columns=['ticker', 'name'])
                add_log(f"âŒ [INIT] ë°ì´í„° ë¡œë“œ ì—ëŸ¬: {str(e)}")
        else:
            st.session_state['portfolio_df'] = pd.DataFrame(columns=['ticker', 'name'])

def save_state_to_csv():
    if 'portfolio_df' in st.session_state:
        df = st.session_state['portfolio_df']
        df = df.reset_index(drop=True)
        st.session_state['portfolio_df'] = df 
        try:
            with open(CSV_FILE, 'w', encoding='utf-8', newline='') as f:
                df.to_csv(f, index=False)
                f.flush()
                os.fsync(f.fileno()) 
            add_log(f"ğŸ’¾ [SAVE] íŒŒì¼ ì €ì¥ ì™„ë£Œ.")
        except Exception as e:
            add_log(f"âŒ [SAVE] íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def add_ticker_logic():
    raw_input = st.session_state.get('new_ticker_input', '')
    if raw_input:
        add_log(f"â• [ADD] í‹°ì»¤ ì¶”ê°€ ìš”ì²­: '{raw_input}'")
        tickers = [t.strip().upper() for t in raw_input.split(',')]
        df = st.session_state['portfolio_df']
        existing_tickers = df['ticker'].values
        
        new_rows = []
        for ticker in tickers:
            if ticker and ticker not in existing_tickers:
                # ë©”íƒ€ë°ì´í„° í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ì´ë¦„ í™•ë³´ ì‹œë„
                meta = fetch_metadata_robust(ticker)
                name = meta.get('name', ticker)
                new_rows.append({'ticker': ticker, 'name': name})
                add_log(f"   -> ì¶”ê°€: {ticker} ({name})")
            else:
                add_log(f"   -> ì¤‘ë³µ ìŠ¤í‚µ: {ticker}")
        
        if new_rows:
            new_df = pd.DataFrame(new_rows)
            df = pd.concat([df, new_df], ignore_index=True)
            st.session_state['portfolio_df'] = df
            save_state_to_csv()
            
    st.session_state['new_ticker_input'] = ""

load_data_to_state()

if 'del_ticker' in st.query_params:
    del_ticker = st.query_params['del_ticker']
    if 'portfolio_df' in st.session_state:
        df = st.session_state['portfolio_df']
        df = df[df['ticker'] != del_ticker]
        st.session_state['portfolio_df'] = df
        save_state_to_csv()
        if f"chk_{del_ticker}" in st.session_state:
            del st.session_state[f"chk_{del_ticker}"]
    st.query_params.clear()
    st.rerun()

# ---------------------------------------------------------
# 3. ìœ í‹¸ë¦¬í‹° & ê°•ë ¥í•œ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (Multi-Layer)
# ---------------------------------------------------------
def get_robust_session():
    session = requests.Session()
    # ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ User-Agent ìœ„ì¡°
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    })
    retry = Retry(total=3, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    session.mount('http://', adapter)
    return session

def run_with_timeout(func, args=(), timeout=10):
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(func, *args)
        try: return future.result(timeout=timeout)
        except: return None

def _fetch_history(ticker, period): return yf.Ticker(ticker).history(period=period)
def _fetch_info(ticker): return yf.Ticker(ticker).info

# [í•µì‹¬] ë‹¤ì¤‘ ì†ŒìŠ¤ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ê¸°
def fetch_metadata_robust(ticker):
    """
    1ì°¨: yfinance API
    2ì°¨: Yahoo Finance ì›¹ ìŠ¤í¬ë˜í•‘ (Fallback)
    """
    add_log(f"ğŸ•µï¸ [META] {ticker} ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
    
    # 1. yfinance ì‹œë„
    try:
        info = run_with_timeout(_fetch_info, args=(ticker,), timeout=6)
        if info and 'shortName' in info:
            name = info.get('shortName') or info.get('longName') or ticker
            sector = info.get('sector', 'Unknown')
            industry = info.get('industry', 'Unknown')
            add_log(f"   âœ… [Source: API] Name: {name}, Sec: {sector}")
            return {'name': name, 'sector': sector, 'industry': industry}
    except: pass

    # 2. ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œë„ (Fallback)
    try:
        add_log(f"   âš ï¸ [Fallback] ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œë„...")
        url = f"https://finance.yahoo.com/quote/{ticker}/profile"
        session = get_robust_session()
        resp = session.get(url, timeout=5)
        
        name = ticker
        sector = "Unknown"
        industry = "Unknown"
        
        if resp.status_code == 200:
            txt = resp.text
            # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì´ë¦„, ì„¹í„°, ì‚°ì—… ì¶”ì¶œ ì‹œë„
            name_match = re.search(r'<title>(.*?) \((.*?)\) Company Profile', txt)
            if name_match: name = name_match.group(1).strip()
            
            # Yahoo êµ¬ì¡°ì— ë”°ë¥¸ ê°„ë‹¨ íŒŒì‹± (êµ¬ì¡° ë³€ê²½ì‹œ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ìˆìŒ)
            sec_match = re.search(r'Sector:.*?<span class="value">(.*?)</span>', txt, re.DOTALL) # ì˜ˆì‹œ íŒ¨í„´
            # ì‹¤ì œ ì•¼í›„ í˜ì´ì§€ êµ¬ì¡°ê°€ ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‚¬ìš©
            if "Sector(s)" in txt:
                # ë‹¨ìˆœí™”ëœ ë¡œì§: HTML íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ ì£¼ë³€ ê²€ìƒ‰ (êµ¬í˜„ ë³µì¡ë„ìƒ ìƒëµ í›„ AIì—ê²Œ ìœ„ì„ì´ ë‚˜ìŒ)
                pass 
            
            add_log(f"   âœ… [Source: Web] Name found: {name}")
            return {'name': name, 'sector': sector, 'industry': industry}
    except Exception as e:
        add_log(f"   âŒ [Fallback Error] {e}")

    # 3. ì‹¤íŒ¨ ì‹œ
    add_log(f"   âš ï¸ [Failure] ë©”íƒ€ë°ì´í„° í™•ë³´ ì‹¤íŒ¨. AIì—ê²Œ ìœ„ì„.")
    return {'name': ticker, 'sector': 'Unknown', 'industry': 'Unknown'}

def clean_html_text(text):
    if not text: return ""
    clean = re.sub(r'<[^>]+>', '', text)
    clean = html.unescape(clean)
    clean = " ".join(clean.split())
    return clean

def is_similar(a, b, threshold=0.7):
    if not a or not b: return False
    return SequenceMatcher(None, a, b).ratio() > threshold

def fetch_rss_realtime(url, limit=10):
    try:
        session = get_robust_session()
        response = session.get(url, timeout=5)
        root = ET.fromstring(response.content)
        items = []
        for item in root.findall('./channel/item')[:limit]:
            title = item.find('title').text
            try: dt = parser.parse(item.find('pubDate').text); date_str = dt.strftime("%m-%d %H:%M")
            except: date_str = "ìµœì‹ "
            desc = ""
            if item.find('description') is not None: desc = clean_html_text(item.find('description').text)
            items.append({'title': title, 'link': item.find('link').text, 'date_str': date_str, 'summary': desc})
        return items
    except: return []

def get_realtime_news(ticker, name):
    add_log(f"ğŸ“° [NEWS] {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘")
    news_items = []
    is_kr = bool(re.search(r'\.KS|\.KQ|[0-9]{6}', ticker))
    
    # 1. Yahoo RSS
    if not is_kr:
        try:
            items = fetch_rss_realtime(f"https://finance.yahoo.com/rss/headline?s={ticker}", limit=5)
            for i in items: i['source'] = "Yahoo"; news_items.append(i)
        except: pass

    # 2. Google News RSS
    search_query = f'"{name}"' if is_kr else f'{ticker} stock'
    q_encoded = urllib.parse.quote(search_query)
    try:
        url = f"https://news.google.com/rss/search?q={q_encoded}&hl=ko&gl=KR&ceid=KR:ko"
        items = fetch_rss_realtime(url, limit=5)
        for i in items: i['source'] = "Google"; news_items.append(i)
    except: pass
    
    return news_items[:7]

def get_financial_metrics(ticker):
    info = run_with_timeout(_fetch_info, args=(ticker,), timeout=5)
    if not info: return {}
    def fmt(k): v = info.get(k); return f"{v:,.2f}" if isinstance(v,(int,float)) else "N/A"
    return {
        "FCF": fmt('freeCashflow'), "CurrRatio": fmt('currentRatio'),
        "Debt/Eq": fmt('debtToEquity'), "ROE": fmt('returnOnEquity'),
        "Rev": fmt('totalRevenue'), "NetInc": fmt('netIncome')
    }

def sanitize_text(text):
    text = text.replace('$', '\$')
    return re.sub(r'\n\s*\n+', '\n\n', text).strip()

def collapse_sidebar():
    js = """<script>var closeBtn = window.parent.document.querySelector('[data-testid="stSidebarExpandedControl"]');if (closeBtn) {closeBtn.click();}</script>"""
    st.components.v1.html(js, height=0, width=0)

def start_analysis_process(targets, mode, is_prompt_only):
    st.session_state['is_analyzing'] = True
    st.session_state['targets_to_run'] = targets
    st.session_state['current_mode'] = mode
    st.session_state['prompt_mode'] = is_prompt_only
    st.session_state['analysis_results'] = {} 
    st.session_state['proc_index'] = 0
    st.session_state['proc_stage'] = 1 

def generate_with_fallback(prompt, api_key, start_model):
    genai.configure(api_key=api_key)
    # [ì¤‘ìš”] ì œë¯¸ë‚˜ì´ ê²€ìƒ‰ ë„êµ¬ í™œì„±í™” (ì •ë³´ ë¶€ì¡±ì‹œ ì‚¬ìš©)
    tools = [{'google_search': {}}] 
    
    fallback_chain = [start_model, "gemini-2.0-flash-lite-preview-02-05", "gemini-1.5-flash", "gemini-1.5-pro"]
    
    for model_name in fallback_chain:
        try:
            add_log(f"   Attempting AI: {model_name}")
            # ë„êµ¬ ì‚¬ìš© ì„¤ì •
            model = genai.GenerativeModel(model_name, tools=tools)
            response = model.generate_content(prompt)
            return response.text, model_name 
        except Exception as e:
            add_log(f"   âš ï¸ AI Fail ({model_name}): {e}")
            time.sleep(1)
            continue
    raise Exception("All AI models failed.")

def handle_search_click(mode, is_prompt):
    raw_input = st.session_state.get("s_input", "")
    if raw_input:
        targets = [t.strip() for t in raw_input.split(',') if t.strip()]
        start_analysis_process(targets, mode, is_prompt)
    else: st.warning("í‹°ì»¤ ì…ë ¥ í•„ìš”")

def step_fetch_data(ticker, mode):
    add_log(f"ğŸ“¦ [STEP 1] Data Fetch: {ticker}")
    
    # 1. ì´ˆê¸°í™” (ì´ì „ ë°ì´í„° ì”ì¬ ì œê±°)
    clean_code = re.sub(r'[^0-9a-zA-Z]', '', ticker)
    is_kr = (".KS" in ticker or ".KQ" in ticker or (ticker.isdigit() and len(ticker)==6))
    tv_symbol = f"KRX:{clean_code}" if is_kr else ticker
    
    # 2. ë©”íƒ€ë°ì´í„° í™•ë³´ (ë‹¤ì¤‘ ì†ŒìŠ¤)
    meta = fetch_metadata_robust(ticker)
    stock_name = meta['name']
    sector = meta['sector']
    industry = meta['industry']

    # 3. ì£¼ê°€ ë°ì´í„°
    period = st.session_state.get('selected_period_str', '1y')
    df = run_with_timeout(_fetch_history, args=(ticker, period), timeout=8)
    if df is None: df = pd.DataFrame()

    data_summary = "No Data"
    if not df.empty:
        curr = df['Close'].iloc[-1]
        data_summary = f"Current: {curr:.2f}\nRecent Data:\n{df.tail(5).to_string()}"
    
    # 4. ì¬ë¬´ ë° ë‰´ìŠ¤
    fin_str = "N/A"
    news_text = "N/A"
    if mode not in ["10K", "10Q", "8K"]:
        try: fin_str = str(get_financial_metrics(ticker))
        except: pass
        
        if st.session_state.get('use_news', True):
            news = get_realtime_news(ticker, stock_name)
            if news: news_text = "\n".join([f"- [{n['source']}] {n['title']} ({n['date_str']})" for n in news])

    # 5. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    selected_focus_list = []
    for opt in opt_targets:
        if st.session_state.get(f"focus_{opt}", True): selected_focus_list.append(opt)
    focus = ", ".join(selected_focus_list)
    viewpoint = st.session_state.get('selected_viewpoint', 'General')
    analysis_depth = st.session_state.get('analysis_depth', "2. í‘œì¤€")

    # [í•µì‹¬] ì‹œë‚˜ë¦¬ì˜¤ í™•ë¥  ìš”ì²­ ë° ë©”íƒ€ë°ì´í„° ìê°€ ìˆ˜ì • ì§€ì‹œ
    level_instruction = ""
    scenario_instruction = ""
    if "5." in analysis_depth:
        scenario_instruction = """
        \n[í•„ìˆ˜ ìš”ì²­: ì‹œë‚˜ë¦¬ì˜¤ë³„ í™•ë¥  ëª…ì‹œ]
        ê²°ë¡  ë¶€ë¶„ì— ë°˜ë“œì‹œ 'ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„(Scenario Analysis)' ì„¹ì…˜ì„ ë§Œë“¤ê³ , ë‹¤ìŒ 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ **ì‹¤í˜„ ê°€ëŠ¥ í™•ë¥ (%)**ê³¼ **ê·¸ ì´ìœ (Rationale)**ë¥¼ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
        1. ğŸš€ Bull Case (ë‚™ê´€ì ): í™•ë¥  OO% - ì´ìœ  ìš”ì•½
        2. â– Base Case (ê¸°ë³¸): í™•ë¥  OO% - ì´ìœ  ìš”ì•½
        3. ğŸ’§ Bear Case (ë¹„ê´€ì ): í™•ë¥  OO% - ì´ìœ  ìš”ì•½
        (ì„¸ í™•ë¥ ì˜ í•©ì€ 100%ê°€ ë˜ë„ë¡ í•˜ì‹­ì‹œì˜¤.)
        """
        level_instruction += scenario_instruction

    if "íˆ¬ìì„±í–¥ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì ì •ë³´ìœ ë¹„ì¤‘" in focus:
        level_instruction += """
        \n[íŠ¹ë³„ ì§€ì‹œ: íˆ¬ìì„±í–¥ë³„ ë¹„ì¤‘ ì œì•ˆ]
        ê²°ë¡ ì— ê³µê²©ì /ì¤‘ë¦½ì /ë³´ìˆ˜ì  íˆ¬ììë³„ ê¶Œì¥ ë³´ìœ  ë¹„ì¤‘(%)ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤.
        """

    growth_value_logic = """
    [í•µì‹¬: ì„±ì¥ì£¼ vs ê°€ì¹˜ì£¼ íŒë‹¨]
    ë¨¼ì € ì´ ê¸°ì—…ì´ ì„±ì¥ì£¼ì¸ì§€ ê°€ì¹˜ì£¼ì¸ì§€ ê·œì •í•˜ê³ , ê·¸ì— ë§ëŠ” í•µì‹¬ ì§€í‘œ(ë§¤ì¶œì„±ì¥ vs ë°°ë‹¹/ì ìœ ìœ¨ ë“±)ë¥¼ ìš°ì„  ë¶„ì„í•˜ì‹­ì‹œì˜¤.
    """
    
    # [ê°€ì¥ ì¤‘ìš”í•œ ë³€ê²½ì ] ë©”íƒ€ë°ì´í„° ë³´ì™„ ì§€ì‹œ (Prompt Injection)
    # ì •ë³´ê°€ Unknownì´ë©´ AIê°€ ì§ì ‘ Google Search ë„êµ¬ë¥¼ ì¨ì„œ ì±„ìš°ë„ë¡ ê°•ì œ
    metadata_instruction = f"""
    [ëŒ€ìƒ ì •ë³´]
    - í‹°ì»¤: {ticker}
    - ì…ë ¥ëœ ê¸°ì—…ëª…: {stock_name}
    - ì…ë ¥ëœ ì„¹í„°: {sector}
    - ì…ë ¥ëœ ì‚°ì—…: {industry}

    **[CRITICAL INSTRUCTION]**
    ë§Œì•½ ìœ„ 'ì…ë ¥ëœ ê¸°ì—…ëª…', 'ì„¹í„°', 'ì‚°ì—…' ì •ë³´ê°€ 'Unknown'ì´ê±°ë‚˜, í‹°ì»¤({ticker})ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ì •ë³´(ì˜ˆ: soun í‹°ì»¤ì— nvda ì´ë¦„ ë“±)ë¼ê³  íŒë‹¨ëœë‹¤ë©´,
    **ì¦‰ì‹œ Google Search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ìµœì‹  ì •ë³´ë¥¼ ì°¾ì•„ë‚¸ ë’¤, ë³´ê³ ì„œ ì„œë‘ì— ì˜¬ë°”ë¥¸ ê¸°ì—…ëª…/ì„¹í„°/ì‚°ì—…ì„ ëª…ì‹œí•˜ê³  ë¶„ì„ì„ ì§„í–‰í•˜ì‹­ì‹œì˜¤.**
    ì…ë ¥ëœ ì •ë³´ë¥¼ ë§¹ì‹ í•˜ì§€ ë§ê³ , ë‹¹ì‹ ì˜ ì§€ì‹ê³¼ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš°ì„ ì‹œí•˜ì‹­ì‹œì˜¤.
    """

    korean_enforcement = "\n\n**[ì¤‘ìš”] ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ ìì—°ìŠ¤ëŸ¬ìš´ 'í•œêµ­ì–´(Korean)'ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**"

    base_prompt = f"""
    [ì—­í• ] ì›”ê°€ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸
    {metadata_instruction}
    [ëª¨ë“œ] {mode}
    [ì¤‘ì  ë¶„ì„] {focus}
    [ê´€ì ] {viewpoint}
    [ì‹¬ë„] {analysis_depth}
    
    {growth_value_logic}
    {level_instruction}
    
    [ë°ì´í„° ìš”ì•½]
    {data_summary}
    [ì¬ë¬´] {fin_str}
    [ë‰´ìŠ¤] {news_text}
    
    [ì§€ì‹œì‚¬í•­]
    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ì ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    ë°ì´í„°ê°€ ë¶€ì¡±í•œ ë¶€ë¶„ì€ 'Google Search'ë¥¼ í†µí•´ ë³´ì™„í•˜ì‹­ì‹œì˜¤.
    {korean_enforcement}
    """

    if mode == "10K": prompt = base_prompt.replace("[ëª¨ë“œ] MAIN", "[ëª¨ë“œ] 10-K ë¶„ì„").replace("íˆ¬ì ë³´ê³ ì„œ", "10-K ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ")
    elif mode == "10Q": prompt = base_prompt.replace("[ëª¨ë“œ] MAIN", "[ëª¨ë“œ] 10-Q ì‹¤ì  ë¶„ì„")
    elif mode == "8K": prompt = base_prompt.replace("[ëª¨ë“œ] MAIN", "[ëª¨ë“œ] 8-K ê³µì‹œ ì†ë³´")
    else: prompt = base_prompt

    st.session_state['temp_data'] = {
        'name': stock_name, 'tv_symbol': tv_symbol, 'is_kr': is_kr,
        'df': df, 'prompt': prompt, 'news': []
    }
    return True

# ---------------------------------------------------------
# 5. UI êµ¬ì„±
# ---------------------------------------------------------
st.sidebar.subheader("ğŸ¯ ë¶„ì„ ì˜µì…˜")
selected_viewpoint = st.sidebar.select_slider("", options=list(viewpoint_mapping.keys()), value="ì¤‘ê¸° (6ê°œì›”~1ë…„)", label_visibility="collapsed")
viewpoint_mapping = {"ë‹¨ê¸° (1ì£¼~1ê°œì›”)": "3mo", "ìŠ¤ìœ™ (1~3ê°œì›”)": "6mo", "ì¤‘ê¸° (6ê°œì›”~1ë…„)": "2y", "ì¥ê¸° (1~3ë…„)": "5y"}
st.session_state['selected_period_str'] = viewpoint_mapping[selected_viewpoint]
st.session_state['selected_viewpoint'] = selected_viewpoint

analysis_levels = ["1.ìš”ì•½", "2.í‘œì¤€", "3.ì‹¬ì¸µ", "4.ì „ë¬¸ê°€", "5.ì‹œë‚˜ë¦¬ì˜¤"]
analysis_depth = st.sidebar.select_slider("", options=analysis_levels, value=analysis_levels[-1], label_visibility="collapsed")
st.session_state['analysis_depth'] = analysis_depth

st.session_state['use_news'] = st.sidebar.toggle("ë‰´ìŠ¤ ë°ì´í„° ë°˜ì˜", value=True)

def toggle_focus_all():
    new_state = st.session_state['focus_all']
    for opt in opt_targets: st.session_state[f"focus_{opt}"] = new_state

with st.sidebar.expander("â˜‘ï¸ ì¤‘ì  ë¶„ì„ í•­ëª©", expanded=False):
    st.checkbox("ì „ì²´ ì„ íƒ", key="focus_all", on_change=toggle_focus_all)
    for opt in opt_targets: st.checkbox(opt, key=f"focus_{opt}")

api_key = st.secrets.get("GEMINI_API_KEY", None)
if not api_key: st.sidebar.error("Secretsì— 'GEMINI_API_KEY' í•„ìš”")

tab_search, tab_fav = st.sidebar.tabs(["âš¡ ê²€ìƒ‰", "â­ í¬íŠ¸í´ë¦¬ì˜¤"])
prompt_mode_search = False
prompt_mode_port = False

with tab_search:
    st.markdown("<br>", unsafe_allow_html=True) 
    single_input = st.text_input("í‹°ì»¤ (ì˜ˆ: 005930.KS)", key="s_input")
    c_chk, c_btn = st.columns([0.5, 0.5])
    with c_chk: prompt_mode_search = st.checkbox("â˜‘ï¸ í”„ë¡¬í”„íŠ¸ë§Œ", key="chk_prompt_single", value=True)
    with c_btn: 
        if api_key or prompt_mode_search:
            st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", key="btn_s_main", 
                    on_click=handle_search_click, args=("MAIN", prompt_mode_search))
        else: st.button("ğŸ” ì‹œì‘", disabled=True)
    
    st.markdown("##### ğŸ“‘ ê³µì‹œ ë¶„ì„")
    c1, c2, c3 = st.columns(3)
    with c1: st.button("10-K", key="btn_s_10k", on_click=handle_search_click, args=("10K", prompt_mode_search))
    with c2: st.button("10-Q", key="btn_s_10q", on_click=handle_search_click, args=("10Q", prompt_mode_search))
    with c3: st.button("8-K", key="btn_s_8k", on_click=handle_search_click, args=("8K", prompt_mode_search))

# [í¬íŠ¸í´ë¦¬ì˜¤ ì„¹ì…˜] - ë™ì¼ ìœ ì§€, ì½”ë“œ ê¸¸ì´ìƒ í•µì‹¬ ë¡œì§ë§Œ ë³´ì¡´
selected_tickers = []
if 'selected' in st.query_params:
    selected_tickers = [t.strip() for t in st.query_params['selected'].split(',') if t.strip()]

with tab_fav:
    st.markdown("<br>", unsafe_allow_html=True)
    c1, c2 = st.columns([0.75, 0.25])
    with c1: st.text_input("ì¢…ëª© ì¶”ê°€", key="new_ticker_input", label_visibility="collapsed")
    with c2: st.button("â•", on_click=add_ticker_logic)

    fav_df = st.session_state.get('portfolio_df', pd.DataFrame())
    if not fav_df.empty:
        # JS Grid ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼ (ìƒëµ ì—†ì´ ì‚¬ìš©í•˜ë ¤ë©´ ì´ì „ ì½”ë“œì˜ Grid ë¶€ë¶„ ë³µì‚¬ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ê°„ëµí™”ëœ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œì‹œ (ê³µê°„ ë¬¸ì œ)
        st.write("í¬íŠ¸í´ë¦¬ì˜¤ ëª©ë¡ (ì‚­ì œ: ì²´í¬ í•´ì œ)")
        to_remove = []
        for idx, row in fav_df.iterrows():
            is_sel = st.checkbox(f"{row['ticker']} ({row['name']})", key=f"chk_p_{row['ticker']}", value=(row['ticker'] in selected_tickers))
            if is_sel and row['ticker'] not in selected_tickers: selected_tickers.append(row['ticker'])
            elif not is_sel and row['ticker'] in selected_tickers: selected_tickers.remove(row['ticker'])
    
    c_chk_p, c_btn_p = st.columns([0.5, 0.5])
    with c_chk_p: prompt_mode_port = st.checkbox("â˜‘ï¸ í”„ë¡¬í”„íŠ¸ë§Œ", key="chk_prompt_port", value=True)
    with c_btn_p: 
        if st.button("ğŸš€ ì¢…í•© ë¶„ì„", type="primary"):
            start_analysis_process(selected_tickers, "MAIN", prompt_mode_port)

st.sidebar.markdown('<hr>', unsafe_allow_html=True)
st.sidebar.subheader("ğŸ¤– ëª¨ë¸")
st.sidebar.selectbox("ëª¨ë¸", ["gemini-2.0-flash-lite-preview-02-05", "gemini-1.5-pro", "gemini-1.5-flash"], key='selected_model')

with st.sidebar.expander("ğŸ“œ ë¡œê·¸"):
    st.text_area("Log", value="\n".join(st.session_state['log_buffer']), height=200)

# ---------------------------------------------------------
# 6. ì‹¤í–‰ ì»¨íŠ¸ë¡¤ëŸ¬
# ---------------------------------------------------------
st.title(f"ğŸ“ˆ AI Hyper-Analyst V86")

if st.session_state['is_analyzing']:
    targets = st.session_state['targets_to_run']
    idx = st.session_state['proc_index']
    stage = st.session_state['proc_stage']
    
    if not targets or idx >= len(targets):
        st.success("ì™„ë£Œ!")
        st.session_state['is_analyzing'] = False
        st.rerun()

    curr = targets[idx]
    st.progress((idx * 2 + (1 if stage > 1 else 0)) / (len(targets) * 2), text=f"ë¶„ì„ ì¤‘: {curr}")

    if stage == 1:
        collapse_sidebar()
        with st.spinner(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘: {curr}"):
            step_fetch_data(curr, st.session_state['current_mode'])
            st.session_state['proc_stage'] = 2
            st.rerun()
            
    elif stage == 2:
        temp = st.session_state['temp_data']
        if st.session_state['prompt_mode']:
            res = {'report': "í”„ë¡¬í”„íŠ¸ ìƒì„±ë¨", 'status': 'manual', 'prompt': temp['prompt']}
        else:
            with st.spinner("AI ë¶„ì„ ì¤‘..."):
                try:
                    txt, model = generate_with_fallback(temp['prompt'], api_key, st.session_state['selected_model'])
                    res = {'report': txt, 'status': 'success', 'model': model}
                except Exception as e:
                    res = {'report': str(e), 'status': 'error'}
        
        st.session_state['analysis_results'][curr] = {**temp, **res}
        st.session_state['proc_index'] = idx + 1
        st.session_state['proc_stage'] = 1
        st.rerun()

# ê²°ê³¼ ì¶œë ¥
if st.session_state['analysis_results']:
    for t, d in st.session_state['analysis_results'].items():
        with st.expander(f"ğŸ“Š {d['name']} ({t}) ê²°ê³¼", expanded=True):
            if d['status'] == 'manual': st.code(d['prompt'])
            else: st.markdown(d['report'])
            if not d['df'].empty: st.line_chart(d['df']['Close'])
